# Comment Toxicity Prediction

This repository contains the code and resources for building and deploying a comment toxicity classification model using deep learning with TensorFlow. The model is trained to predict whether a given comment contains toxic content or not. It is based on the Jigsaw Toxic Comment Classification Challenge dataset from Kaggle.

## Table of Contents

- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Conclusion](#conclusion)

## Dataset

The dataset used for training and evaluation is the [Jigsaw Toxic Comment Classification Challenge dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data) from Kaggle. It consists of comments and associated toxicity labels, including categories such as toxic, severe toxic, obscene, threat, insult, and identity hate.

## Installation

1. Clone this repository:

```bash
git clone https://github.com/Siddharth-2382/Comment-Toxicity-Prediction.git
cd Comment-Toxicity-Prediction
```

## Usage

1. Open the Jupyter notebook: Launch Jupyter Notebook and navigate to the `Comment-Toxicity-Prediction.ipynb` notebook.
2. Follow the instructions in the notebook: Run each cell in the notebook to preprocess the dataset, train the model, and evaluate its performance.

## Conclusion

In conclusion, this project has successfully developed a comment toxicity classification model using deep learning and TensorFlow. The Bidirectional LSTM architecture efficiently captures sequential patterns in comments, enabling accurate toxicity predictions. Through training and evaluation on the Jigsaw Toxic Comment Classification Challenge dataset, the model demonstrates its effectiveness.

Moving forward, the model's capabilities can be refined to contribute to healthier online conversations by identifying and mitigating toxic content.

Thank you for your engagement and interest in this project.
